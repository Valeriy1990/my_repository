import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from keras import models
from keras import layers
from keras import optimizers

c = np.array([-40, -10, 0, 8, 15, 22, 38])
f = np.array([-40, 14, 32, 46, 59, 72, 100])

"""Jпределим модель НС, как последовательную, т.е. состоящую из слоев, идущих друг за другом
Добавим в эту модель слой нейронов, состоящий из одного нашего выходного нейрона, имеющий ровно один вход и линейную активационную функцию"""

model = models.Sequential(layers.Dense(units=1, input_shape=(1,), activation='linear'))

'''Здесь units=1 означает один нейрон, а input_shape=(1,) – один вход. 
Конструктор Dense формирует полносвязный слой, то есть, все входы будут связаны со всеми нейронами данного слоя. 
В нашем простейшем случае – это связь W1 и дополнительно, автоматически, для каждого нейрона добавляется смещение – bias.''' 

'''Теперь, когда структура НС определена, ее нужно скомпилировать, указав критерий качества и способ оптимизации алгоритма градиентного спуска. 
В рамках данной задачи мы выберем минимум среднего квадрата ошибки и оптимизацию по Adam'''

model.compile(loss='mean_squared_error', optimizer=optimizers.Adam(0.1))

"""Здесь передается обучающая выборка для входных и выходных значений, затем, число эпох, 
т.е. выборка будет пропущена через сеть 500 раз и на каждой итерации будут корректироваться весовые коэффициенты и вычисляться значение критерия качества. 
Последний параметр указывает не отображать в консоли текущую информацию при обучении сети"""

log = model.fit(c, f, epochs=500, verbose=False)

plt.plot(log.history['loss'])
plt.grid(True)
plt.show()